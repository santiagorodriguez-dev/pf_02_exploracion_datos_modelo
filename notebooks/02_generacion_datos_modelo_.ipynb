{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Concatenate # type: ignore\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import dotenv # type: ignore\n",
    "dotenv.load_dotenv()\n",
    "from src import support_bd as bd\n",
    "from src import support_tsf as tsf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = bd.select_datos(\"alumnos\")\n",
    "df = df.drop(columns=[\"nombre\", \"apellidos\", \"email\", \"telefono\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preparar los codificadores para las columnas categóricas\n",
    "le_estudios = LabelEncoder()\n",
    "le_especialidad = LabelEncoder()\n",
    "le_ciudad = LabelEncoder()\n",
    "le_sexo = LabelEncoder()\n",
    "\n",
    "# Ajustar los codificadores con los valores únicos de cada columna\n",
    "df[\"estudios\"] = le_estudios.fit_transform(df[\"estudios\"])\n",
    "df[\"especialidad\"] = le_especialidad.fit_transform(df[\"especialidad\"])\n",
    "df[\"ciudad\"] = le_ciudad.fit_transform(df[\"ciudad\"])\n",
    "df[\"sexo\"] = le_sexo.fit_transform(df[\"sexo\"])\n",
    "\n",
    "# Tokenizar y procesar el campo de texto 'motivo_compra'\n",
    "tokenizer = Tokenizer(num_words=5000)  # Limitar a las 5000 palabras más frecuentes\n",
    "tokenizer.fit_on_texts(df[\"motivo_compra\"])\n",
    "df[\"motivo_compra\"] = tokenizer.texts_to_sequences(df[\"motivo_compra\"])\n",
    "\n",
    "# Rellenar las secuencias para que todas tengan la misma longitud\n",
    "max_len = 50  # Máxima longitud de las descripciones\n",
    "df[\"motivo_compra\"] = pad_sequences(df[\"motivo_compra\"], maxlen=max_len).tolist()\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X_numerico = df[[\"edad\", \"estudios\", \"especialidad\", \"sexo\", \"ciudad\"]].values\n",
    "X_texto = np.array(df[\"motivo_compra\"].tolist())\n",
    "y = df[\"comprado\"].values\n",
    "\n",
    "# Escalar los datos numéricos\n",
    "scaler = StandardScaler()\n",
    "X_numerico = scaler.fit_transform(X_numerico)\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_num_train, X_num_test, X_text_train, X_text_test, y_train, y_test = train_test_split(\n",
    "    X_numerico, X_texto, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Crear el modelo combinado\n",
    "# Entrada numérica\n",
    "input_numerico = Input(shape=(X_numerico.shape[1],))\n",
    "numerico = Dense(16, activation=\"relu\")(input_numerico)\n",
    "\n",
    "# Entrada de texto\n",
    "input_texto = Input(shape=(max_len,))\n",
    "texto = Embedding(input_dim=5000, output_dim=64, input_length=max_len)(input_texto)\n",
    "texto = LSTM(32)(texto)\n",
    "\n",
    "# Concatenar entradas\n",
    "concatenado = Concatenate()([numerico, texto])\n",
    "denso = Dense(16, activation=\"relu\")(concatenado)\n",
    "salida = Dense(1, activation=\"sigmoid\")(denso)\n",
    "\n",
    "# Modelo final\n",
    "model = Model(inputs=[input_numerico, input_texto], outputs=salida)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    [X_num_train, X_text_train], y_train,\n",
    "    epochs=3, batch_size=5, validation_data=([X_num_test, X_text_test], y_test)\n",
    ")\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate([X_num_test, X_text_test], y_test, verbose=0)\n",
    "print(f\"Precisión del modelo: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data(row, score):\n",
    "        \n",
    "        score_short = np.round(float(score), decimals=2)\n",
    "        \n",
    "        data ={ \n",
    "            \"email\" : row['email'], \n",
    "            \"score\" : score_short\n",
    "        } \n",
    "        supabase = bd.init_conection_bd()\n",
    "\n",
    "        response = (\n",
    "            supabase.table(\"leads\")\n",
    "            .update({\"score\": data['score']})\n",
    "            .eq(\"email\", data['email'])\n",
    "            .execute())\n",
    "        \n",
    "        print(f\"Registro Actualizado {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads = bd.select_datos(\"leads\")\n",
    "# Iterar sobre las filas\n",
    "for index, row in df_leads.iterrows():\n",
    "    score = tsf.predict(row, le_estudios, le_especialidad, le_ciudad, le_sexo, scaler, tokenizer, max_len, model)\n",
    "    update_data(row, score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
